{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "n_samples = 2000\n",
    "test_samples = 200\n",
    "\n",
    "# load the training and test datasets\n",
    "X_train = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "X_test = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
    "                    np.where(X_train.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "idx = np.append(np.where(X_test.targets == 0)[0][:test_samples], \n",
    "                    np.where(X_test.targets == 1)[0][:test_samples])\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "# Create training and test dataloaders\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 1\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class ConvDenoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvDenoiser, self).__init__()\n",
    "        ## encoder layers ##\n",
    "        # conv layer (depth from 1 --> 32), 3x3 kernels\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  \n",
    "        # conv layer (depth from 32 --> 16), 3x3 kernels\n",
    "        self.conv2 = nn.Conv2d(32, 16, 3, padding=1)\n",
    "        # conv layer (depth from 16 --> 8), 3x3 kernels\n",
    "        self.conv3 = nn.Conv2d(16, 8, 3, padding=1)\n",
    "        # pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        # transpose layer, a kernel of 2 and a stride of 2 will increase the spatial dims by 2\n",
    "        self.t_conv1 = nn.ConvTranspose2d(8, 8, 3, stride=2)  # kernel_size=3 to get to a 7x7 image output\n",
    "        # two more transpose layers with a kernel of 2\n",
    "        self.t_conv2 = nn.ConvTranspose2d(8, 16, 2, stride=2)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(16, 32, 2, stride=2)\n",
    "        # one, final, normal conv layer to decrease the depth\n",
    "        self.conv_out = nn.Conv2d(32, 1, 3, padding=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## encode ##\n",
    "        # add hidden layers with relu activation function\n",
    "        # and maxpooling after\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # add second hidden layer\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        # add third hidden layer\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = self.pool(x)  # compressed representation\n",
    "        \n",
    "        ## decode ##\n",
    "        # add transpose conv layers, with relu activation function\n",
    "        x = F.leaky_relu(self.t_conv1(x))\n",
    "        x = F.leaky_relu(self.t_conv2(x))\n",
    "        x = F.leaky_relu(self.t_conv3(x))\n",
    "        # transpose again, output should have a sigmoid applied\n",
    "        x = F.sigmoid(self.conv_out(x))\n",
    "                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n",
      "ConvDenoiser(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (t_conv1): ConvTranspose2d(8, 8, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (t_conv2): ConvTranspose2d(8, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (t_conv3): ConvTranspose2d(16, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (conv_out): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_gaussian_noise(images, sigma=0.9):\n",
    "\treturn torch.clamp(torch.distributions.Normal(0, sigma).sample(images.shape) + images, 0., 1.)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "\n",
    "# initialize the NN\n",
    "model = ConvDenoiser().to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.035085\n",
      "Epoch: 2 \tTraining Loss: 0.026808\n",
      "Epoch: 3 \tTraining Loss: 0.025218\n",
      "Epoch: 4 \tTraining Loss: 0.024588\n",
      "Epoch: 5 \tTraining Loss: 0.024097\n",
      "Epoch: 6 \tTraining Loss: 0.023860\n",
      "Epoch: 7 \tTraining Loss: 0.023381\n",
      "Epoch: 8 \tTraining Loss: 0.023286\n",
      "Epoch: 9 \tTraining Loss: 0.023160\n",
      "Epoch: 10 \tTraining Loss: 0.022884\n",
      "Epoch: 11 \tTraining Loss: 0.022726\n",
      "Epoch: 12 \tTraining Loss: 0.022703\n",
      "Epoch: 13 \tTraining Loss: 0.022478\n",
      "Epoch: 14 \tTraining Loss: 0.022408\n",
      "Epoch: 15 \tTraining Loss: 0.022460\n",
      "Epoch: 16 \tTraining Loss: 0.022275\n",
      "Epoch: 17 \tTraining Loss: 0.022169\n",
      "Epoch: 18 \tTraining Loss: 0.022053\n",
      "Epoch: 19 \tTraining Loss: 0.022052\n",
      "Epoch: 20 \tTraining Loss: 0.022011\n",
      "Epoch: 21 \tTraining Loss: 0.022043\n",
      "Epoch: 22 \tTraining Loss: 0.021944\n",
      "Epoch: 23 \tTraining Loss: 0.021785\n",
      "Epoch: 24 \tTraining Loss: 0.021890\n",
      "Epoch: 25 \tTraining Loss: 0.021774\n",
      "Epoch: 26 \tTraining Loss: 0.021653\n",
      "Epoch: 27 \tTraining Loss: 0.021534\n",
      "Epoch: 28 \tTraining Loss: 0.021717\n",
      "Epoch: 29 \tTraining Loss: 0.021524\n",
      "Epoch: 30 \tTraining Loss: 0.021669\n",
      "Epoch: 31 \tTraining Loss: 0.021571\n",
      "Epoch: 32 \tTraining Loss: 0.021383\n",
      "Epoch: 33 \tTraining Loss: 0.021630\n",
      "Epoch: 34 \tTraining Loss: 0.021559\n",
      "Epoch: 35 \tTraining Loss: 0.021343\n",
      "Epoch: 36 \tTraining Loss: 0.021411\n",
      "Epoch: 37 \tTraining Loss: 0.021350\n",
      "Epoch: 38 \tTraining Loss: 0.021397\n",
      "Epoch: 39 \tTraining Loss: 0.021382\n",
      "Epoch: 40 \tTraining Loss: 0.021384\n",
      "Epoch: 41 \tTraining Loss: 0.021343\n",
      "Epoch: 42 \tTraining Loss: 0.021375\n",
      "Epoch: 43 \tTraining Loss: 0.021247\n",
      "Epoch: 44 \tTraining Loss: 0.021227\n",
      "Epoch: 45 \tTraining Loss: 0.021289\n",
      "Epoch: 46 \tTraining Loss: 0.021359\n",
      "Epoch: 47 \tTraining Loss: 0.021234\n",
      "Epoch: 48 \tTraining Loss: 0.021119\n",
      "Epoch: 49 \tTraining Loss: 0.021103\n",
      "Epoch: 50 \tTraining Loss: 0.021172\n"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 50\n",
    "\n",
    "# for adding noise to images\n",
    "noise_factor=0.5\n",
    "\n",
    "losses = []\n",
    "psnrs = []\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data in train_loader:\n",
    "        # _ stands in for labels, here\n",
    "        # no need to flatten images\n",
    "        images, _ = data\n",
    "        \n",
    "        # add noise to the original images\n",
    "        noisy_imgs = add_gaussian_noise(images)\n",
    "                \n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        ## forward pass: compute predicted outputs by passing *noisy* images to the model\n",
    "        outputs = model(noisy_imgs.to(device))\n",
    "        # calculate the loss\n",
    "        # the \"target\" is still the original, not-noisy images\n",
    "        loss = criterion(outputs, images.to(device))\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "\n",
    "        batch_avg_psnr = 0.0\n",
    "        outputs = outputs.detach().view(len(images), 1, 28, 28)\n",
    "        for i in range(len(images)):\n",
    "            org = np.transpose(images[i], (1, 2, 0)).detach().numpy()\n",
    "            denoise = np.transpose(outputs[i], (1, 2, 0)).detach().numpy()\n",
    "            batch_avg_psnr += psnr(org, denoise)\n",
    "            \n",
    "    # print avg training statistics \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "\n",
    "    losses.append(train_loss)\n",
    "    psnrs.append(batch_avg_psnr)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch, \n",
    "        train_loss\n",
    "    ))\n",
    "\n",
    "# losses = np.array(losses)\n",
    "# to csv\n",
    "# np.savetxt('classical_losses.csv', losses, delimiter=',')\n",
    "\n",
    "# psnrs = np.array(psnrs)\n",
    "# to csv\n",
    "# np.savetxt('classical_psnrs.csv', psnrs, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncols = 10\n",
    "# fig, axes = plt.subplots(nrows=3, ncols=ncols, sharex=True, sharey=True, figsize=(25,7))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for k in range(ncols):\n",
    "#         dataiter = iter(test_loader)\n",
    "#         images, labels = next(dataiter)\n",
    "#         noisy_imgs = add_gaussian_noise(images, sigma=0.25)\n",
    "#         output = model(noisy_imgs.to(device)).to(device)\n",
    "#         noisy_imgs = noisy_imgs.numpy()\n",
    "#         output = output.view(1, 1, 28, 28)\n",
    "#         output = output.cpu().detach().numpy()\n",
    "#         col_axes = axes[:, k]\n",
    "#         col_axes[0].imshow(np.squeeze(images), cmap='gist_gray')\n",
    "#         col_axes[1].imshow(np.squeeze(noisy_imgs), cmap='gist_gray')\n",
    "#         col_axes[2].imshow(np.squeeze(output), cmap='gist_gray')\n",
    "\n",
    "#     plt.savefig('classical_denoising.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "# avg_psnr = 0\n",
    "# test_size = 0\n",
    "\n",
    "# for data in test_loader:\n",
    "#     images = data[0]\n",
    "#     noisy_imgs = add_gaussian_noise(images)\n",
    "#     output = model(noisy_imgs)\n",
    "#     output = output.view(len(images), 1, 28, 28)\n",
    "#     output = output.detach().cpu()\n",
    "#     batch_avg_psnr = 0\n",
    "#     for i in range(len(images)):\n",
    "#         org = np.transpose(images[i], (1, 2, 0)).numpy()\n",
    "#         denoise = np.transpose(output[i], (1, 2, 0)).numpy()\n",
    "#         batch_avg_psnr += psnr(org, denoise)\n",
    "#     avg_psnr += batch_avg_psnr\n",
    "#     test_size += len(images)\n",
    "# print(\n",
    "#     \"On Test data of {} examples:\\nAverage PSNR: {:.3f}\".format(\n",
    "#         test_size, avg_psnr / test_size\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8269261543144479\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "    images = data[0]\n",
    "    noisy_imgs = add_gaussian_noise(images, sigma=1)\n",
    "    output = model(noisy_imgs)\n",
    "    output = output.view(len(images), 1, 28, 28)\n",
    "    output = output.detach().cpu()\n",
    "    # for i in range(len(images)):\n",
    "    #     org = images[i].numpy().squeeze()\n",
    "    #     denoise = output[i].numpy().squeeze()\n",
    "    #     ssim_val = ssim(org, denoise, full=True, data_range=data_range)\n",
    "    images = images.numpy().squeeze()\n",
    "    output = output.numpy().squeeze()\n",
    "    ssim_val = ssim(images, output, data_range=1.0)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(images, cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(output, cmap='gray')\n",
    "print(ssim_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
